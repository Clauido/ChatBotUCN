services:
  db-vector:
    profiles: ["cpu", "nvidia"]
    container_name: ucenin-pgvector
    image: pgvector/pgvector:pg16
    restart: unless-stopped
    ports: #Only for dev!
      - "${PGV_PORT}:5432"
    volumes:
      - ./Database/Dump/dump.sql:/docker-entrypoint-initdb.d/init_pgvector.sql
    environment:
      POSTGRES_USER: "${PGV_USER}"
      POSTGRES_PASSWORD: "${PGV_PASSWORD}" #Change me!
      POSTGRES_DB: "${PGV_DATABASE_NAME}"

  api:
    profiles: ["cpu", "nvidia"]
    container_name: ucenin-api
    build:
      context: ./api
      dockerfile: dockerfile
    restart: unless-stopped
    ports:
      - "${API_PORT}:8000"
    environment:
      PGV_USER: "${PGV_USER}"
      PGV_PASSWORD: "${PGV_PASSWORD}" #Match password!
      PGV_HOST: "${PGV_HOST}"
      PGV_PORT: "${PGV_PORT}"
      PGV_DATABASE_NAME: "${PGV_DATABASE_NAME}"
      EMBEDDING_MODEL: "${EMBEDDING_MODEL}"
      UCN_MODEL_NAME: "${UCN_MODEL_NAME}"
      OLLAMA_PORT: ${OLLAMA_PORT}
      OLLAMA_HOST: ${OLLAMA_HOST}
    depends_on:
      - db-vector

  frontend:
    profiles: ["cpu", "nvidia"]
    container_name: ucenin-frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    environment:
      FRONT_API_URL: "http://localhost:8000"
    depends_on:
      - api

  model-cpu:
    profiles: ["cpu"]
    container_name: ucenin-ollama
    build:
      context: ./model
      dockerfile: dockerfile
    restart: unless-stopped
    ports:
      - "${OLLAMA_PORT}:11434"

  model-gpu:
    profiles: ["nvidia"]
    container_name: ucenin-ollama
    build:
      context: ./model
      dockerfile: dockerfile
    restart: unless-stopped
    ports:
      - "${OLLAMA_PORT}:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
